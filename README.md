# TNSDC : Generative AI for Engineering Project

## Student Information

- **Name:** R B Shyamala
- **Register Number:** 2021503558
- **Year:** III Year
- **Course:** Generative AI for Engineering (E2324)
- **NMID:** 1E352D1BBE931BE9376478F8D8893207

## Project Details

- **Domain:** Deep Learning
- **Title:** Image Classification using CNN

## Overview

This project focuses on implementing a Convolutional Neural Network (CNN) for image classification tasks. The goal is to develop a model capable of accurately classifying images into predefined categories i.e, cat vs. dog based on their visual features.

## Project Structure

- **Dataset:** The project utilizes a dataset of labeled images for training, validation, and testing purposes. This dataset contains images belonging to different classes or categories. (Drive link: https://drive.google.com/file/d/1K5wAmMq1bCuZ44C-cLR4X5DgU5kiNILp/view?usp=sharing)
- **Preprocessing:** Data preprocessing techniques are applied to prepare the dataset for model training. This includes tasks such as resizing images, normalization, and splitting the dataset into training, validation, and test sets.
- **Model Architecture:** A CNN architecture is designed and implemented using TensorFlow and Keras. This architecture consists of convolutional layers, pooling layers, and fully connected layers to extract features from input images and make predictions.
- **Training:** The model is trained using the training dataset and validated using the validation dataset. Training involves optimizing the model parameters (e.g., weights and biases) to minimize the loss function and improve classification accuracy.
- **Evaluation:** The trained model's performance is evaluated using the test dataset to assess its accuracy and generalization capabilities. Metrics such as accuracy, precision, recall, and F1-score may be used for evaluation.
- **Visualization:** Visualizations are generated to analyze the training process, including loss curves, accuracy curves, and confusion matrices. Additionally, activation maps may be visualized to understand how the model makes predictions.
